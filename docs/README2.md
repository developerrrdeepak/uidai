# ğŸ“ Detailed File Structure & Project Directory

**Project:** Financial Inclusion Scout with Aadhaar Early-Warning Intelligence  
**UIDAI ID:** UIDAI_12208

---

## ğŸ“‚ Complete Directory Structure

```
uidai data/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                                    # Main project documentation
â”œâ”€â”€ ğŸ“„ README2.md                                   # This file - Detailed structure
â”œâ”€â”€ ğŸ“„ CLEANED_FILES_VERIFICATION.md                # Data verification report
â”œâ”€â”€ ğŸ“„ ML_TRAINING_GUIDE.md                         # ML training documentation
â”‚
â”œâ”€â”€ ğŸ“Š RAW DATA FILES (Input)
â”‚   â”œâ”€â”€ api_data_aadhar_enrolment_0_500000.csv      # Enrollment data part 1
â”‚   â”œâ”€â”€ api_data_aadhar_enrolment_500000_1000000.csv # Enrollment data part 2
â”‚   â”œâ”€â”€ api_data_aadhar_enrolment_1000000_1006029.csv # Enrollment data part 3
â”‚   â”œâ”€â”€ api_data_aadhar_demographic_*.csv           # Demographic data files
â”‚   â””â”€â”€ api_data_aadhar_biometric_*.csv             # Biometric update data files
â”‚
â”œâ”€â”€ ğŸ§¹ DATA CLEANING SCRIPTS
â”‚   â”œâ”€â”€ analysis.py                                 # Enrollment data cleaning
â”‚   â”‚   â”œâ”€â”€ Input: api_data_aadhar_enrolment_*.csv
â”‚   â”‚   â”œâ”€â”€ Output: aadhaar_enrollment_cleaned.csv
â”‚   â”‚   â”œâ”€â”€ Functions: State name normalization, date parsing
â”‚   â”‚   â””â”€â”€ Records: 1,006,029 â†’ Cleaned dataset
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis2.py                                # Demographic data cleaning
â”‚   â”‚   â”œâ”€â”€ Input: api_data_aadhar_demographic_*.csv
â”‚   â”‚   â”œâ”€â”€ Output: aadhaar_demographic_cleaned.csv
â”‚   â”‚   â”œâ”€â”€ Functions: Age group standardization, gender normalization
â”‚   â”‚   â””â”€â”€ Records: 882,744 rows, 814 districts
â”‚   â”‚
â”‚   â””â”€â”€ analysis3.py                                # Biometric data cleaning
â”‚       â”œâ”€â”€ Input: api_data_aadhar_biometric_*.csv
â”‚       â”œâ”€â”€ Output: aadhaar_biometric_cleaned.csv
â”‚       â”œâ”€â”€ Functions: Time-series alignment, outlier handling
â”‚       â””â”€â”€ Records: 917,008 rows, 907 districts
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ CLEANED DATA FILES (Output)
â”‚   â”œâ”€â”€ aadhaar_enrollment_cleaned.csv              # 1M+ rows, enrollment data
â”‚   â”‚   â””â”€â”€ Columns: date, state_clean, district_clean, pincode,
â”‚   â”‚               age_0_5, age_5_17, age_18_greater, total_enrolment
â”‚   â”‚
â”‚   â”œâ”€â”€ aadhaar_demographic_cleaned.csv             # 882K rows, demographic data
â”‚   â”‚   â””â”€â”€ Columns: state, district, age_group, gender, 
â”‚   â”‚               enrolment_count, time_period
â”‚   â”‚
â”‚   â””â”€â”€ aadhaar_biometric_cleaned.csv               # 917K rows, biometric updates
â”‚       â””â”€â”€ Columns: state, district, time_period, 
â”‚                   biometric_updates, update_type
â”‚
â”œâ”€â”€ ğŸ¤– MACHINE LEARNING MODELS
â”‚   â”œâ”€â”€ train_model.py                              # ML model training script
â”‚   â”‚   â”œâ”€â”€ Algorithms: Logistic Regression, Random Forest, 
â”‚   â”‚   â”‚              Gradient Boosting, Decision Tree, SVM, KNN
â”‚   â”‚   â”œâ”€â”€ Output: best_model.pkl, scaler.pkl
â”‚   â”‚   â”œâ”€â”€ Metrics: Accuracy, Precision, Recall, F1-Score
â”‚   â”‚   â””â”€â”€ Visualizations: 5 comparison charts
â”‚   â”‚
â”‚   â”œâ”€â”€ complete_unified_system.py                  # Integrated 3-model pipeline
â”‚   â”‚   â”œâ”€â”€ Model 1: Anomaly Detection (Z-score)
â”‚   â”‚   â”œâ”€â”€ Model 2: Risk Scoring (Normalized indicators)
â”‚   â”‚   â”œâ”€â”€ Model 3: Rule-Based Classification
â”‚   â”‚   â””â”€â”€ Output: Unified risk assessment
â”‚   â”‚
â”‚   â””â”€â”€ rule_based_risk_classification_model3.py    # Model 3 standalone
â”‚       â”œâ”€â”€ Risk Types: Administrative Disruption, DBT Failure,
â”‚       â”‚              Child Welfare Exclusion, Gender Barrier,
â”‚       â”‚              Migration/Crisis Shock
â”‚       â””â”€â”€ Output: Risk type + Recommended action
â”‚
â”œâ”€â”€ ğŸ“ˆ VISUALIZATION GENERATORS
â”‚   â”œâ”€â”€ model1_single_chart.py                      # Model 1 dashboard generator
â”‚   â”‚   â”œâ”€â”€ Input: aadhaar_biometric_cleaned.csv, 
â”‚   â”‚   â”‚         aadhaar_demographic_cleaned.csv
â”‚   â”‚   â”œâ”€â”€ Output: MODEL1_COMPREHENSIVE_DASHBOARD.png
â”‚   â”‚   â”œâ”€â”€ Charts: KPI cards, coverage histogram, scatter plot,
â”‚   â”‚   â”‚          top anomalies, statistics table
â”‚   â”‚   â””â”€â”€ Size: 1920x1080px, 300 DPI
â”‚   â”‚
â”‚   â”œâ”€â”€ model2_single_chart.py                      # Model 2 dashboard generator
â”‚   â”‚   â”œâ”€â”€ Input: Cleaned datasets + risk scores
â”‚   â”‚   â”œâ”€â”€ Output: MODEL2_COMPREHENSIVE_DASHBOARD.png
â”‚   â”‚   â”œâ”€â”€ Charts: Risk level KPIs, distribution, donut chart,
â”‚   â”‚   â”‚          top high-risk districts, statistics
â”‚   â”‚   â””â”€â”€ Size: 1920x1080px, 300 DPI
â”‚   â”‚
â”‚   â””â”€â”€ model3_single_chart.py                      # Model 3 dashboard generator
â”‚       â”œâ”€â”€ Input: Cleaned datasets + classifications
â”‚       â”œâ”€â”€ Output: MODEL3_COMPREHENSIVE_DASHBOARD.png
â”‚       â”œâ”€â”€ Charts: Severity KPIs, risk type distribution,
â”‚       â”‚          stacked bars, top districts, rule logic
â”‚       â””â”€â”€ Size: 1920x1080px, 300 DPI
â”‚
â”œâ”€â”€ ğŸ–¼ï¸ GENERATED VISUALIZATIONS
â”‚   â”œâ”€â”€ model1_visuals/
â”‚   â”‚   â”œâ”€â”€ MODEL1_COMPREHENSIVE_DASHBOARD.png      # Main Model 1 dashboard
â”‚   â”‚   â”œâ”€â”€ anomaly_detection_scatter.png           # Scatter plot
â”‚   â”‚   â”œâ”€â”€ coverage_distribution.png               # Histogram
â”‚   â”‚   â””â”€â”€ top_anomalies.png                       # Bar chart
â”‚   â”‚
â”‚   â”œâ”€â”€ model2_visuals/
â”‚   â”‚   â”œâ”€â”€ MODEL2_COMPREHENSIVE_DASHBOARD.png      # Main Model 2 dashboard
â”‚   â”‚   â”œâ”€â”€ risk_score_distribution.png             # Distribution plot
â”‚   â”‚   â”œâ”€â”€ risk_level_donut.png                    # Donut chart
â”‚   â”‚   â””â”€â”€ high_risk_districts.png                 # Bar chart
â”‚   â”‚
â”‚   â””â”€â”€ model3_visuals/
â”‚       â”œâ”€â”€ MODEL3_COMPREHENSIVE_DASHBOARD.png      # Main Model 3 dashboard
â”‚       â”œâ”€â”€ risk_type_distribution.png              # Bar chart
â”‚       â”œâ”€â”€ severity_stacked.png                    # Stacked bar
â”‚       â””â”€â”€ classification_results.png              # Results table
â”‚
â”œâ”€â”€ ğŸŒ DASHBOARD & API
â”‚   â”œâ”€â”€ api.py                                      # Flask REST API
â”‚   â”‚   â”œâ”€â”€ Port: 5001
â”‚   â”‚   â”œâ”€â”€ Endpoints: /api/districts, /api/stats, /api/high-risk
â”‚   â”‚   â”œâ”€â”€ CORS: Enabled
â”‚   â”‚   â””â”€â”€ Data: Serves cleaned datasets as JSON
â”‚   â”‚
â”‚   â”œâ”€â”€ advanced_dashboard.html                     # React TypeScript dashboard
â”‚   â”‚   â”œâ”€â”€ Framework: React 18 + Babel
â”‚   â”‚   â”œâ”€â”€ Features: 4 tabs, search, filter, export, pagination
â”‚   â”‚   â”œâ”€â”€ Theme: Dark mode with glassmorphism
â”‚   â”‚   â”œâ”€â”€ Charts: Chart.js integration
â”‚   â”‚   â””â”€â”€ API: Connects to Flask backend (port 5001)
â”‚   â”‚
â”‚   â””â”€â”€ app.py                                      # Streamlit dashboard (alternative)
â”‚       â”œâ”€â”€ Framework: Streamlit
â”‚       â”œâ”€â”€ Features: Multi-page app, interactive filters
â”‚       â””â”€â”€ Port: 8501 (default)
â”‚
â”œâ”€â”€ ğŸ–¥ï¸ SCREENSHOTS
â”‚   â”œâ”€â”€ react_dashboard.png                         # React dashboard screenshot
â”‚   â”œâ”€â”€ streamlit_overview.png                      # Streamlit overview
â”‚   â””â”€â”€ api_response.png                            # API response example
â”‚
â”œâ”€â”€ ğŸ’¾ TRAINED MODEL FILES
â”‚   â”œâ”€â”€ best_model.pkl                              # Best performing ML model
â”‚   â”œâ”€â”€ scaler.pkl                                  # Feature scaler
â”‚   â”œâ”€â”€ model_comparison.json                       # Model performance metrics
â”‚   â””â”€â”€ feature_importance.csv                      # Feature importance scores
â”‚
â””â”€â”€ ğŸ“‹ CONFIGURATION FILES
    â”œâ”€â”€ requirements.txt                            # Python dependencies
    â”œâ”€â”€ .gitignore                                  # Git ignore rules
    â””â”€â”€ config.json                                 # Application configuration
```

---

## ğŸ“Š Data Flow Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAW UIDAI DATA FILES                     â”‚
â”‚  (Enrollment, Demographic, Biometric - 1.8M+ records)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DATA CLEANING SCRIPTS                          â”‚
â”‚  analysis.py â†’ analysis2.py â†’ analysis3.py                  â”‚
â”‚  â€¢ State normalization  â€¢ Missing value handling            â”‚
â”‚  â€¢ Date parsing         â€¢ Outlier detection                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CLEANED DATA FILES (CSV)                       â”‚
â”‚  â€¢ aadhaar_enrollment_cleaned.csv                           â”‚
â”‚  â€¢ aadhaar_demographic_cleaned.csv                          â”‚
â”‚  â€¢ aadhaar_biometric_cleaned.csv                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              3-MODEL PIPELINE                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Model 1: Anomaly Detection (Z-score)            â”‚        â”‚
â”‚  â”‚ Output: 229 anomalies detected                  â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                         â”‚                                    â”‚
â”‚                         â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Model 2: Risk Scoring (Normalized)              â”‚        â”‚
â”‚  â”‚ Output: 73 High, 39 Medium, 74 Low Risk         â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                         â”‚                                    â”‚
â”‚                         â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Model 3: Rule-Based Classification              â”‚        â”‚
â”‚  â”‚ Output: Risk type + Recommended action          â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              VISUALIZATION LAYER                            â”‚
â”‚  â€¢ model1_single_chart.py â†’ MODEL1_DASHBOARD.png            â”‚
â”‚  â€¢ model2_single_chart.py â†’ MODEL2_DASHBOARD.png            â”‚
â”‚  â€¢ model3_single_chart.py â†’ MODEL3_DASHBOARD.png            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DASHBOARD & API LAYER                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Flask API      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤  React Dashboard â”‚          â”‚
â”‚  â”‚   (port 5001)    â”‚         â”‚  (HTML/JS/CSS)   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Script Dependencies

### analysis.py
```
Input Files:
  - api_data_aadhar_enrolment_0_500000.csv
  - api_data_aadhar_enrolment_500000_1000000.csv
  - api_data_aadhar_enrolment_1000000_1006029.csv

Output Files:
  - aadhaar_enrollment_cleaned.csv

Dependencies:
  - pandas
  - matplotlib
  - numpy

Key Functions:
  - State name normalization
  - Date parsing and validation
  - Total enrollment calculation
  - Top/Bottom state ranking
  - Time-series visualization
```

### analysis2.py
```
Input Files:
  - api_data_aadhar_demographic_*.csv

Output Files:
  - aadhaar_demographic_cleaned.csv

Dependencies:
  - pandas
  - numpy

Key Functions:
  - Age group standardization
  - Gender normalization
  - District-level aggregation
  - Child enrollment ratio calculation
```

### analysis3.py
```
Input Files:
  - api_data_aadhar_biometric_*.csv

Output Files:
  - aadhaar_biometric_cleaned.csv

Dependencies:
  - pandas
  - numpy

Key Functions:
  - Time-series alignment
  - Biometric update trend analysis
  - Rolling window imputation
  - Update readiness calculation
```

### train_model.py
```
Input Files:
  - aadhaar_enrollment_cleaned.csv
  - aadhaar_demographic_cleaned.csv
  - aadhaar_biometric_cleaned.csv

Output Files:
  - best_model.pkl
  - scaler.pkl
  - model_comparison.json
  - 5 visualization charts

Dependencies:
  - pandas
  - numpy
  - scikit-learn
  - matplotlib
  - seaborn

Algorithms:
  1. Logistic Regression
  2. Random Forest Classifier
  3. Gradient Boosting Classifier
  4. Decision Tree Classifier
  5. Support Vector Machine (SVM)
  6. K-Nearest Neighbors (KNN)
```

### complete_unified_system.py
```
Input Files:
  - aadhaar_enrollment_cleaned.csv
  - aadhaar_demographic_cleaned.csv
  - aadhaar_biometric_cleaned.csv

Output:
  - Console output with risk assessment
  - Integrated 3-model results

Dependencies:
  - pandas
  - numpy
  - scikit-learn

Models:
  - Model 1: Anomaly Detection
  - Model 2: Risk Scoring
  - Model 3: Rule-Based Classification
```

### model1_single_chart.py
```
Input Files:
  - aadhaar_biometric_cleaned.csv
  - aadhaar_demographic_cleaned.csv

Output Files:
  - model1_visuals/MODEL1_COMPREHENSIVE_DASHBOARD.png

Dependencies:
  - pandas
  - matplotlib
  - seaborn
  - numpy

Chart Components:
  - 4 KPI cards (Total Districts, Anomalies, Normal, Rate)
  - Coverage distribution histogram
  - Biometric vs Demographic scatter plot
  - Top 10 anomalous districts bar chart
  - Detailed statistics table
```

### model2_single_chart.py
```
Input Files:
  - aadhaar_enrollment_cleaned.csv
  - aadhaar_demographic_cleaned.csv
  - aadhaar_biometric_cleaned.csv

Output Files:
  - model2_visuals/MODEL2_COMPREHENSIVE_DASHBOARD.png

Dependencies:
  - pandas
  - matplotlib
  - seaborn
  - numpy

Chart Components:
  - 3 Risk level KPI cards (High/Medium/Low)
  - Risk score distribution by level
  - Risk level proportion donut chart
  - Top 12 high-risk districts (color-coded)
  - Risk scoring statistics table
```

### model3_single_chart.py
```
Input Files:
  - aadhaar_enrollment_cleaned.csv
  - aadhaar_demographic_cleaned.csv
  - aadhaar_biometric_cleaned.csv

Output Files:
  - model3_visuals/MODEL3_COMPREHENSIVE_DASHBOARD.png

Dependencies:
  - pandas
  - matplotlib
  - seaborn
  - numpy

Chart Components:
  - 3 Severity KPI cards (High/Medium/Low)
  - Risk type distribution bar chart
  - Severity by risk type stacked bar
  - Top 10 high-risk districts (color = risk type)
  - Classification statistics and rule logic
```

### api.py
```
Input Files:
  - aadhaar_enrollment_cleaned.csv
  - aadhaar_demographic_cleaned.csv
  - aadhaar_biometric_cleaned.csv

Dependencies:
  - flask
  - flask-cors
  - pandas

Endpoints:
  GET /api/districts       - All district data
  GET /api/stats          - Summary statistics
  GET /api/high-risk      - High-risk districts only
  GET /api/search?q=name  - Search districts

Port: 5001
CORS: Enabled for localhost
```

### advanced_dashboard.html
```
Dependencies:
  - React 18 (CDN)
  - Babel Standalone (CDN)
  - Chart.js (CDN)
  - Fetch API

Features:
  - 4 Interactive tabs
  - Real-time search
  - Risk level filtering
  - Export to CSV
  - Pagination (20 items/page)
  - Dark theme with glassmorphism

API Connection:
  - Backend: http://localhost:5001
  - Auto-refresh on data change
```

---

## ğŸ“¦ File Size Information

| File | Size | Records | Districts |
|------|------|---------|-----------|
| aadhaar_enrollment_cleaned.csv | ~150 MB | 1,006,029 | 750+ |
| aadhaar_demographic_cleaned.csv | ~80 MB | 882,744 | 814 |
| aadhaar_biometric_cleaned.csv | ~90 MB | 917,008 | 907 |
| best_model.pkl | ~5 MB | - | - |
| MODEL1_DASHBOARD.png | ~2 MB | - | - |
| MODEL2_DASHBOARD.png | ~2 MB | - | - |
| MODEL3_DASHBOARD.png | ~2 MB | - | - |

---

## ğŸš€ Execution Order

### Complete Pipeline Execution

```bash
# Step 1: Data Cleaning (Run in order)
python analysis.py      # Creates aadhaar_enrollment_cleaned.csv
python analysis2.py     # Creates aadhaar_demographic_cleaned.csv
python analysis3.py     # Creates aadhaar_biometric_cleaned.csv

# Step 2: Model Training (Optional)
python train_model.py   # Creates best_model.pkl, scaler.pkl

# Step 3: Generate Visualizations
python model1_single_chart.py  # Creates MODEL1_DASHBOARD.png
python model2_single_chart.py  # Creates MODEL2_DASHBOARD.png
python model3_single_chart.py  # Creates MODEL3_DASHBOARD.png

# Step 4: Run Dashboard
python api.py           # Start Flask API on port 5001
# Then open advanced_dashboard.html in browser
```

### Quick Start (Pre-cleaned Data)

```bash
# If cleaned CSV files already exist:

# Generate visualizations
python model1_single_chart.py
python model2_single_chart.py
python model3_single_chart.py

# Start dashboard
python api.py
start advanced_dashboard.html
```

---

## ğŸ” Key Metrics by File

### aadhaar_enrollment_cleaned.csv
- Total Records: 1,006,029
- States/UTs: 36
- Districts: 750+
- Date Range: 2015-2024
- Total Enrollments: 1.3+ Billion

### aadhaar_demographic_cleaned.csv
- Total Records: 882,744
- Districts: 814
- Age Groups: 3 (0-5, 5-17, 18+)
- Gender Categories: 2 (Male, Female)

### aadhaar_biometric_cleaned.csv
- Total Records: 917,008
- Districts: 907
- Update Types: Multiple
- Time Period: Monthly aggregation

### Model Results
- Districts Analyzed: 917
- Anomalies Detected: 229 (25%)
- High Risk Districts: 73
- Medium Risk Districts: 39
- Low Risk Districts: 74
- Risk Types: 4

---

## ğŸ“ File Naming Conventions

### Data Files
- `aadhaar_*_cleaned.csv` - Cleaned datasets
- `api_data_aadhar_*_*.csv` - Raw UIDAI data

### Model Files
- `*_model.pkl` - Trained ML models
- `*_scaler.pkl` - Feature scalers
- `model_comparison.json` - Performance metrics

### Visualization Files
- `MODEL*_COMPREHENSIVE_DASHBOARD.png` - Main dashboards
- `*_distribution.png` - Distribution charts
- `*_scatter.png` - Scatter plots
- `*_bar.png` - Bar charts

### Script Files
- `analysis*.py` - Data cleaning scripts
- `train_*.py` - Model training scripts
- `model*_single_chart.py` - Visualization generators
- `*_model*.py` - Model implementation scripts

---

## ğŸ› ï¸ Technology Stack by Component

### Data Processing
- **Language:** Python 3.11
- **Libraries:** Pandas, NumPy
- **Format:** CSV

### Machine Learning
- **Framework:** Scikit-learn
- **Algorithms:** 6 classifiers
- **Serialization:** Pickle

### Visualization
- **Static:** Matplotlib, Seaborn
- **Interactive:** Chart.js
- **Format:** PNG (300 DPI)

### Dashboard
- **Frontend:** React 18 + TypeScript (Babel)
- **Backend:** Flask + Flask-CORS
- **Alternative:** Streamlit

### API
- **Framework:** Flask
- **Protocol:** REST
- **Format:** JSON
- **Port:** 5001

---

## ğŸ“§ Contact & Support

**Team Leader:** Deepak  
**Team Members:** Adarsh Kumar Pandey, Ajay Rajora  
**UIDAI ID:** UIDAI_12208

---

**Last Updated:** January 2025  
**Version:** 1.0.0
